// automatically generated by the FlatBuffers compiler, do not modify
extern crate flatbuffers;
use self::flatbuffers::{EndianScalar, Follow};
use super::*;
use std::cmp::Ordering;
use std::mem;
// struct Metadata, aligned to 8
#[repr(transparent)]
#[derive(Clone, Copy, PartialEq)]
pub struct Metadata(pub [u8; 16]);
impl Default for Metadata {
    fn default() -> Self {
        Self([0; 16])
    }
}
impl std::fmt::Debug for Metadata {
    fn fmt(&self, f: &mut std::fmt::Formatter) -> std::fmt::Result {
        f.debug_struct("Metadata")
            .field("timestamp", &self.timestamp())
            .field("offset", &self.offset())
            .finish()
    }
}

impl flatbuffers::SimpleToVerifyInSlice for Metadata {}
impl flatbuffers::SafeSliceAccess for Metadata {}
impl<'a> flatbuffers::Follow<'a> for Metadata {
    type Inner = &'a Metadata;
    #[inline]
    fn follow(buf: &'a [u8], loc: usize) -> Self::Inner {
        <&'a Metadata>::follow(buf, loc)
    }
}
impl<'a> flatbuffers::Follow<'a> for &'a Metadata {
    type Inner = &'a Metadata;
    #[inline]
    fn follow(buf: &'a [u8], loc: usize) -> Self::Inner {
        flatbuffers::follow_cast_ref::<Metadata>(buf, loc)
    }
}
impl<'b> flatbuffers::Push for Metadata {
    type Output = Metadata;
    #[inline]
    fn push(&self, dst: &mut [u8], _rest: &[u8]) {
        let src = unsafe {
            ::std::slice::from_raw_parts(self as *const Metadata as *const u8, Self::size())
        };
        dst.copy_from_slice(src);
    }
}
impl<'b> flatbuffers::Push for &'b Metadata {
    type Output = Metadata;

    #[inline]
    fn push(&self, dst: &mut [u8], _rest: &[u8]) {
        let src = unsafe {
            ::std::slice::from_raw_parts(*self as *const Metadata as *const u8, Self::size())
        };
        dst.copy_from_slice(src);
    }
}

impl<'a> flatbuffers::Verifiable for Metadata {
    #[inline]
    fn run_verifier(
        v: &mut flatbuffers::Verifier,
        pos: usize,
    ) -> Result<(), flatbuffers::InvalidFlatbuffer> {
        use self::flatbuffers::Verifiable;
        v.in_buffer::<Self>(pos)
    }
}

impl<'a> Metadata {
    #[allow(clippy::too_many_arguments)]
    pub fn new(timestamp: i64, offset: i64) -> Self {
        let mut s = Self([0; 16]);
        s.set_timestamp(timestamp);
        s.set_offset(offset);
        s
    }

    pub fn timestamp(&self) -> i64 {
        let mut mem = core::mem::MaybeUninit::<i64>::uninit();
        unsafe {
            core::ptr::copy_nonoverlapping(
                self.0[0..].as_ptr(),
                mem.as_mut_ptr() as *mut u8,
                core::mem::size_of::<i64>(),
            );
            mem.assume_init()
        }
        .from_little_endian()
    }

    pub fn set_timestamp(&mut self, x: i64) {
        let x_le = x.to_little_endian();
        unsafe {
            core::ptr::copy_nonoverlapping(
                &x_le as *const i64 as *const u8,
                self.0[0..].as_mut_ptr(),
                core::mem::size_of::<i64>(),
            );
        }
    }

    pub fn offset(&self) -> i64 {
        let mut mem = core::mem::MaybeUninit::<i64>::uninit();
        unsafe {
            core::ptr::copy_nonoverlapping(
                self.0[8..].as_ptr(),
                mem.as_mut_ptr() as *mut u8,
                core::mem::size_of::<i64>(),
            );
            mem.assume_init()
        }
        .from_little_endian()
    }

    pub fn set_offset(&mut self, x: i64) {
        let x_le = x.to_little_endian();
        unsafe {
            core::ptr::copy_nonoverlapping(
                &x_le as *const i64 as *const u8,
                self.0[8..].as_mut_ptr(),
                core::mem::size_of::<i64>(),
            );
        }
    }
}
